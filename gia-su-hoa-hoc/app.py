import streamlit as st
import os
from google import genai
from google.genai import types
from pypdf import PdfReader
from docx import Document
# Sá»­ dá»¥ng phiÃªn báº£n tá»‘i Æ°u cá»§a sentence_transformers cho FAISS
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss

# --- Cáº¤U HÃŒNH á»¨NG Dá»¤NG ---
st.set_page_config(page_title="Gia SÆ° HÃ³a Há»c THCS", page_icon="ğŸ§ª")
st.title("ğŸ§ª Gia SÆ° HÃ³a Há»c THCS")

# --- KHá»I Táº O GEMINI CLIENT ---
@st.cache_resource
def get_gemini_client():
    """Khá»Ÿi táº¡o Gemini Client tá»« Streamlit Secrets hoáº·c biáº¿n mÃ´i trÆ°á»ng."""
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        st.session_state.admin_password = st.secrets.get("ADMIN_PASSWORD", "211191")
        return genai.Client(api_key=api_key)
    except (AttributeError, KeyError):
        try:
            st.session_state.admin_password = os.getenv("ADMIN_PASSWORD", "211191")
            return genai.Client()
        except Exception:
            st.error("âŒ KhÃ´ng tÃ¬m tháº¥y GEMINI API Key. Vui lÃ²ng thÃªm vÃ o Streamlit Secrets.")
            st.stop()

client = get_gemini_client()

# --- QUáº¢N LÃ TÃ€I LIá»†U ---
knowledge_path = "knowledge_base"
os.makedirs(knowledge_path, exist_ok=True)

def extract_text_from_file(filepath):
    """TrÃ­ch xuáº¥t vÄƒn báº£n tá»« cÃ¡c loáº¡i file Ä‘Æ°á»£c há»— trá»£."""
    ext = os.path.splitext(filepath)[1].lower()
    try:
        if ext == ".txt":
            with open(filepath, "r", encoding="utf-8") as f:
                return f.read()
        elif ext == ".pdf":
            reader = PdfReader(filepath)
            # DÃ¹ng extract_text() an toÃ n hÆ¡n
            text = "\n".join([p.extract_text() or "" for p in reader.pages])
            return text
        elif ext == ".docx":
            doc = Document(filepath)
            return "\n".join([p.text for p in doc.paragraphs])
    except Exception as e:
        st.warning(f"Lá»—i Ä‘á»c file {filepath}: {e}")
        return None
    return None

@st.cache_resource
def load_knowledge_base():
    """Táº£i vÃ  trÃ­ch xuáº¥t ná»™i dung tá»« thÆ° má»¥c knowledge_base."""
    texts = []
    for fn in os.listdir(knowledge_path):
        path = os.path.join(knowledge_path, fn)
        if os.path.splitext(fn)[1].lower() in {".txt", ".pdf", ".docx"}:
            content = extract_text_from_file(path)
            if content and content.strip():
                texts.append({"filename": fn, "content": content})
    return texts

knowledge_texts = load_knowledge_base()

# --- TÃŒM KIáº¾M NGá»® NGHÄ¨A (FAISS) ---
@st.cache_resource
def build_semantic_index(knowledge_texts):
    """XÃ¢y dá»±ng chá»‰ má»¥c FAISS cho tÃ¬m kiáº¿m ngá»¯ nghÄ©a."""
    if not knowledge_texts:
        return None
    # Model embedding Ä‘a ngÃ´n ngá»¯ hiá»‡u quáº£
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    chunks, meta = [], []
    for item in knowledge_texts:
        # Cáº£i thiá»‡n Chunking: Chia theo Ä‘oáº¡n vÄƒn/dÃ²ng lá»›n hÆ¡n 60 kÃ½ tá»±
        for para in item["content"].split("\n"):
            para = para.strip()
            if len(para) > 60:
                chunks.append(para)
                meta.append(item["filename"])

    emb = model.encode(chunks, normalize_embeddings=True)
    index = faiss.IndexFlatIP(emb.shape[1])
    index.add(np.array(emb, dtype=np.float32))

    return {"index": index, "model": model, "chunks": chunks, "meta": meta}

semantic_index = build_semantic_index(knowledge_texts)

def search_knowledge_semantic(query, top_k=6): # ÄÃ£ tÄƒng top_k lÃªn 5 Ä‘á»ƒ Ä‘áº£m báº£o láº¥y Ä‘á»§ ngá»¯ cáº£nh
    """TÃ¬m kiáº¿m cÃ¡c Ä‘oáº¡n tÃ i liá»‡u liÃªn quan nháº¥t."""
    if not semantic_index:
        return None
    model = semantic_index["model"]
    index = semantic_index["index"]
    chunks = semantic_index["chunks"]
    meta = semantic_index["meta"]

    q_emb = model.encode([query], normalize_embeddings=True)
    D, I = index.search(np.array(q_emb, dtype=np.float32), top_k)

    results = []
    for idx, score in zip(I[0], D[0]):
        # NgÆ°á»¡ng Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng: loáº¡i bá» káº¿t quáº£ kÃ©m liÃªn quan
        if score < 0.25:
            continue
        results.append(f"ğŸ“˜ [TÃ i liá»‡u: {meta[idx]}]\n{chunks[idx]}")
    return "\n\n---\n".join(results) if results else None

# --- Há»† THá»NG CHAT ---
if "chat_session" not in st.session_state:
    system_instruction = r"""
Báº¡n lÃ  "Gia SÆ° AI HÃ³a há»c THCS" â€” chuyÃªn nghiá»‡p, thÃ¢n thiá»‡n, vÃ  kiÃªn nháº«n.
âœ… Æ¯U TIÃŠN TUYá»†T Äá»I: Náº¿u cÃ³ tÃ i liá»‡u liÃªn quan trong 'ğŸ“š KIáº¾N THá»¨C Cáº¦N THAM KHáº¢O', báº¡n PHáº¢I dá»±a hoÃ n toÃ n vÃ o Ä‘Ã³ Ä‘á»ƒ tráº£ lá»i.
Chá»‰ khi khÃ´ng cÃ³ kiáº¿n thá»©c nÃ o phÃ¹ há»£p, báº¡n má»›i Ä‘Æ°á»£c phÃ©p dÃ¹ng kiáº¿n thá»©c ná»n.
Má»i cÃ´ng thá»©c vÃ  phÆ°Æ¡ng trÃ¬nh pháº£i hiá»ƒn thá»‹ báº±ng LaTeX. CÃ¢u tráº£ lá»i pháº£i báº±ng tiáº¿ng Viá»‡t, cÃ³ giáº£i thÃ­ch tá»«ng bÆ°á»›c.
"""
    config = types.GenerateContentConfig(system_instruction=system_instruction)
    # ÄÃ£ Ä‘á»•i model sang gemini-2.5-flash
    st.session_state.chat_session = client.chats.create(model="gemini-2.5-flash", config=config)

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- GIAO DIá»†N ---
uploaded_file = st.file_uploader("ğŸ“· Táº£i áº£nh bÃ i táº­p (JPG/PNG)", type=["jpg", "jpeg", "png"])
user_question = st.chat_input("âœï¸ Nháº­p cÃ¢u há»i HÃ³a há»c...")

if user_question:
    kb_context = search_knowledge_semantic(user_question)
    contents = []

    if uploaded_file:
        img_part = types.Part.from_bytes(data=uploaded_file.read(), mime_type=uploaded_file.type)
        contents.append(img_part)

    # ğŸš¨ Cáº¤U TRÃšC PROMPT Má»šI ÄÆ¯á»¢C Tá»I Æ¯U HÃ“A RAG
    if kb_context:
        full_prompt = f"""
â— Báº¡n PHáº¢I TUYá»†T Äá»I dá»±a vÃ o thÃ´ng tin trong pháº§n dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i vÃ  trÃ­ch dáº«n nguá»“n (VD: Theo [TÃªn file]) khi sá»­ dá»¥ng.
Náº¿u cÃ¢u há»i khÃ´ng náº±m trong tÃ i liá»‡u nÃ y, hÃ£y tráº£ lá»i: "Kiáº¿n thá»©c nÃ y khÃ´ng cÃ³ trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p."

ğŸ“š KIáº¾N THá»¨C Cáº¦N THAM KHáº¢O:
{kb_context}

---
CÃ¢u há»i cá»§a há»c sinh:
{user_question}
"""
    else:
        full_prompt = f"""
KhÃ´ng cÃ³ tÃ i liá»‡u tham kháº£o liÃªn quan.
HÃ£y tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c ná»n táº£ng cá»§a báº¡n, theo chÆ°Æ¡ng trÃ¬nh HÃ³a há»c THCS (2018).

CÃ¢u há»i:
{user_question}
"""

    contents.append(full_prompt)

    with st.chat_message("Há»c sinh"):
        st.markdown(user_question)
    st.session_state.messages.append({"role": "Há»c sinh", "content": user_question})

    with st.spinner("â³ Gia sÆ° Ä‘ang tráº£ lá»i..."):
        try:
            # Gá»­i tin nháº¯n
            response = st.session_state.chat_session.send_message(contents)
            reply = response.text
        except Exception as e:
            # Xá»­ lÃ½ lá»—i API/Máº¡ng/Timeout rÃµ rÃ ng hÆ¡n
            reply = f"âš ï¸ Lá»—i xá»­ lÃ½ API Gemini: {type(e).__name__}: {e}. Vui lÃ²ng thá»­ láº¡i hoáº·c há»i cÃ¢u khÃ¡c."

    with st.chat_message("Gia SÆ°"):
        st.markdown(reply)
    st.session_state.messages.append({"role": "Gia SÆ°", "content": reply})
    st.rerun()

# --- KHU Vá»°C QUáº¢N TRá»Š ---
with st.sidebar:
    st.header("ğŸ” Khu vá»±c quáº£n trá»‹")
    pwd = st.text_input("Nháº­p máº­t kháº©u admin:", type="password")
    if "admin_password" in st.session_state and pwd == st.session_state.admin_password:
        st.success("âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng!")
        st.info(f"Tá»•ng sá»‘ tÃ i liá»‡u: **{len(knowledge_texts)}**")
        st.markdown("ğŸ“‚ ThÆ° má»¥c: `/knowledge_base` (chá»©a tÃ i liá»‡u .pdf, .docx, .txt)")
        st.markdown("ğŸ” Sau khi thÃªm tÃ i liá»‡u, **restart láº¡i app** Ä‘á»ƒ cáº­p nháº­t.")
    elif pwd:
        st.error("âŒ Sai máº­t kháº©u!")
